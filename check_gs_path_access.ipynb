{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required source files and packages\n",
    "from __future__ import print_function\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from IPython.display import Image,display\n",
    "import dalmatian as dm\n",
    "from IPython.core.display import HTML \n",
    "import sys\n",
    "sys.path.insert(0, '../JKBio/')\n",
    "from IPython.core.debugger import set_trace\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext rpy2.ipython\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check google bucket access\n",
    "\n",
    "The use of this notebook is to determine for any workspace which files (input files and outputs from running workflows) the user does not have access to. In particular, running this notebook will generate a list of the buckets used in the workspace that the user cannot access.\n",
    "\n",
    "The user will need to obtain access to these buckets before they will be able to execute all of the workflows. That being said, if the user is only interested in one or two select workflows, the below code can be edited such that the user can determine what they'll need to get access to in order to run that particular workflow.\n",
    "\n",
    "This notebook also finds google storage file paths that ahve been directly handed into a workflow as an input parameter. This isn't good practice, and should probably be fixed if found by putting the file into into workspace data and then updating the workflow input parameter to point to the appropriate item in the workspace data. In particular, currently this method just identifies bucket paths (not the actual file path). But this can easily be changed if one of these inputs is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current directory\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_list_of_lists(lol):\n",
    "    flat_list = []\n",
    "    for sublist in lol:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "    return(flat_list)\n",
    "\n",
    "def str_remove_quotes_brackets(string):\n",
    "    string = string.replace(\"'\",\"\")\n",
    "    string = string.replace('\"','') # check: does adding this break anything? no.\n",
    "    string = string.replace(\"[\", \"\")\n",
    "    string = string.replace(\"]\",\"\")\n",
    "    return(string)\n",
    "\n",
    "def str_to_list_if_comma(string):\n",
    "    if \",\" in string: # this string is actually a list! break it up\n",
    "        result = [x.strip() for x in string.split(',')]\n",
    "        return(result)\n",
    "    else: # just a string\n",
    "        return(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to check whether the entity contains any gs bucket link.\n",
    "# we also need to deal with chance that we're being passed multiple paths (should be comma separated)\n",
    "# If it does, we want to check access using gsutil. If we don't have access, add the link to the noAccess links.\n",
    "# path may be given as a single path or a character string with a list of paths (e.g. \"gs://path/1, gs://path/2\")\n",
    "\n",
    "# format lists from terra TSVs: terra sometimes has things as str that are actually lists\n",
    "def str_to_list_remove_quotes_brackets(string):\n",
    "    if \",\" in string: # this string is actually a list! break it up\n",
    "        string = string.replace(\"'\",\"\")\n",
    "        string = string.replace(\"[\", \"\")\n",
    "        string = string.replace(\"]\",\"\")\n",
    "        result = [x.strip() for x in string.split(',')]\n",
    "        return(result)\n",
    "    else: # just a string\n",
    "        return(string)\n",
    "\n",
    "\n",
    "def check_access(entity):\n",
    "    # for each value or cell in the dataframe, we will check for gs:// filepaths\n",
    "    # Arg entity: can be either a pandas dataframe or a list (not nested)\n",
    "    if isinstance(entity, list):\n",
    "        flattened_entity = entity # when list as input\n",
    "    else:\n",
    "        flattened_entity = entity.values.flatten().tolist()\n",
    "        \n",
    "    paths = set() # using sets is faster than using lists\n",
    "    # create list of paths\n",
    "    for i in flattened_entity: # for each cell of our entity aka Terra TSV            \n",
    "        if isinstance(i, str):\n",
    "            i = str_remove_quotes_brackets(i)\n",
    "            i = str_to_list_if_comma(i) # this will output a list if the string contains a comma, else a string\n",
    "            if isinstance(i, str) and (i.startswith('gs://') or i.startswith('\"gs://')):\n",
    "#                 ipdb.set_trace()\n",
    "                paths.add(i)\n",
    "        if isinstance(i, list) and np.all([j.startswith('gs://') for j in i if isinstance(j, str)]): # check: but what if it's not a list, but a comma separated string?\n",
    "            paths.update(i)\n",
    "        else:\n",
    "            continue # if it's not a str or a list, then it won't have a file path. Skip.\n",
    "            \n",
    "    print(\"We have a list of \"+str(len(paths))+\" file paths to check for access. \\n\")\n",
    "    \n",
    "    tested_buckets = set()\n",
    "    noAccess = set()\n",
    "    loopNum = 0\n",
    "    for path in paths:\n",
    "        loopNum += 1\n",
    "        if loopNum%10000 == 0:\n",
    "            print(\"We're on path number \"+str(loopNum)+\" of \"+str(len(paths))+\".\")\n",
    "        \n",
    "        bucketpath = re.match(\"^(gs:\\/\\/)([^:\\/\\s]+)\\/\", str(path)) # only check the bucket (more efficient and avoids duplication)\n",
    "        if bucketpath: # found match aka gs bucket path\n",
    "            bucketpath = bucketpath[0] # get the bucket path\n",
    "            if bucketpath not in tested_buckets:\n",
    "                tested_buckets.add(bucketpath)\n",
    "                print(\"We're using gsutil to check access for \"+bucketpath)\n",
    "                # is there a better way to check for access besides using gsutil ls?\n",
    "                accessDeniedCheck = ! gsutil ls {bucketpath} # ideally, faster to check if have full path (not just bucket) because a bucket might have tons of stuff in it.\n",
    "                if \"AccessDeniedException\" in accessDeniedCheck[0]: # shell threw an error: you don't have access\n",
    "                    noAccess.add(bucketpath)\n",
    "    return(noAccess)\n",
    "\n",
    "# create a list of each google storage file path you cannot access\n",
    "def check_workspace_bucket_access(func, wmfrom, wmto=None):\n",
    "    data = {}\n",
    "    try:\n",
    "        a = wmfrom.get_participants()\n",
    "        data.update({'participants': a})\n",
    "    except:\n",
    "        print('no participants')\n",
    "    try:\n",
    "        a = wmfrom.get_samples()\n",
    "        data.update({'samples': a})\n",
    "    except:\n",
    "        print('no samples')\n",
    "    try:\n",
    "        a = wmfrom.get_pair_sets()\n",
    "        data.update({'pair_sets': a})\n",
    "    except:\n",
    "        print('no pair_sets')\n",
    "    try:\n",
    "        a = wmfrom.get_pairs()\n",
    "        data.update({'pairs': a})\n",
    "    except:\n",
    "        print('no pairs')\n",
    "    try:\n",
    "        a = wmfrom.get_sample_sets()\n",
    "        data.update({'sample_sets': a})\n",
    "    except:\n",
    "        print('no sample_sets')\n",
    "#     result = []\n",
    "    result = set()\n",
    "    for key, entity in iter(data.items()): # iter(data.items()) in place of data.iteritems()\n",
    "        print(\"working on key: \", key)\n",
    "#         result += func(entity)\n",
    "        result.update(func(entity))\n",
    "    print(\"\\n Done checking for access.\")\n",
    "    return(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT WORKSPACE INFO HERE\n",
    "Edit the cell below (tagged with 'parameters') to specific your namespace and workspace of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "workspace=\"nci-mimoun-bi-org/PANCAN_TWIST%20copy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmfrom = dm.WorkspaceManager(workspace)\n",
    "func = check_access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmfrom.get_attributes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeniedAccess paths for all workspace entities (e.g. samples, sample sets)\n",
    "\n",
    "This allows the user to see if thet have acccess to all of the files produced by the workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denied_entities = check_workspace_bucket_access(func, wmfrom)\n",
    "denied_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeniedAccess paths for Workspace data TSV\n",
    "\n",
    "This allows the user to see if they have access to all of the buckets used for the workspace data. The workspace data usually contains items that are passed in as input parameters to various workflows. Running workflows may require access to a large portion of the files/objects in the workspace data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting Workspace data TSV values to flattened list (just grabbing the values, not the keys)\n",
    "# on this list, we want to check google bucket access.\n",
    "a = wmfrom.get_attributes()\n",
    "\n",
    "list_dict_inputs_outputs = [list(a.values())] # get values from (nested) dict\n",
    "workspace_data_list = flatten_list_of_lists(list_dict_inputs_outputs)\n",
    "workspace_data_list\n",
    "\n",
    "denied_workspace = check_access(workspace_data_list)\n",
    "denied_workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeniedAccess paths for Workflow inputs and outputs\n",
    "\n",
    "This allows the user to see if they have access to all of the inputs in a workflow that are passed as direct google storage file paths. This direct passing of paths is not good practice, and should probably be fixed at some point when it occurs (except if it's public data that will always be public, like BAMs from Terra tutorials and such)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflows = wmfrom.get_configs()\n",
    "workflows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(workflows) == 0:\n",
    "    print(\"There are no workflows to check.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denied_workflows = set()\n",
    "if len(workflows) != 0:\n",
    "    for i in workflows['name']:\n",
    "        print(i)\n",
    "        # converting Workflow input information to flattened list\n",
    "        try:\n",
    "            a = wmfrom.get_config(i)\n",
    "        except:\n",
    "            print(\"We did not find \"+i+\" in the namespace specified above. \\n\")\n",
    "            continue\n",
    "        list_dict_inputs_outputs = [a.get(key) for key in [\"inputs\", \"outputs\"]] # get values from (nested) dict\n",
    "        list_inputs_outputs = [list(item.values()) for item in list_dict_inputs_outputs] # create list of list from (nested) dict values\n",
    "        workflow_data_list = flatten_list_of_lists(list_inputs_outputs) # flattened list of all inputs to the workflow\n",
    "    #     print(workflow_data_list)\n",
    "    #     print(\"\\n\")\n",
    "    #     print(check_access(workflow_data_list)) # check which ones get added for each workflow\n",
    "    #     print(\"\\n\")\n",
    "\n",
    "        # on this list, we want to check google bucket access.\n",
    "        denied_workflows.update(check_access(workflow_data_list))\n",
    "    #     print(denied_workflows)\n",
    "    #     print(len(denied_workflows))\n",
    "    #     print(\"\\n\")\n",
    "    \n",
    "denied_workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All found DeniedAccess bucket paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denied_all = set()\n",
    "denied_all.update(denied_entities)\n",
    "denied_all.update(denied_workspace)\n",
    "denied_all.update(denied_workflows)\n",
    "denied_all # now this set contains all bucket paths that the user cannot access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(denied_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.787px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
